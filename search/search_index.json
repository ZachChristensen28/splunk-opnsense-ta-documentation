{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00b6 Disclaimer This Splunk App is community driven and not affiliated with the official OPNsense\u00ae Firewall . As such, the included documentation does not contain information on how to get started with this firewall. Rather, this documentation serves as a guide to help visualize the data in Splunk. Please visit https://opnsense.org/ for documentation on installing/configuring your own OPNsense firewall. The OPNsense Add-on allows Splunk data administrators to map the OPNsense\u00ae Firewall events to the CIM enabling the data to be used with other Splunk Apps, such as the OPNsense App for Splunk . Assumptions \u00b6 This documentation assumes the following: You have a working OPNsense firewall. You have a working Splunk environment. Basic understanding of Splunk and OPNsense. About \u00b6 Info Description Version 1.5.1 - Splunkbase | GitHub CIM 4.x Vendor Product Version OPNsense\u00ae 22.x Get Started","title":"Home"},{"location":"#home","text":"Disclaimer This Splunk App is community driven and not affiliated with the official OPNsense\u00ae Firewall . As such, the included documentation does not contain information on how to get started with this firewall. Rather, this documentation serves as a guide to help visualize the data in Splunk. Please visit https://opnsense.org/ for documentation on installing/configuring your own OPNsense firewall. The OPNsense Add-on allows Splunk data administrators to map the OPNsense\u00ae Firewall events to the CIM enabling the data to be used with other Splunk Apps, such as the OPNsense App for Splunk .","title":"Home"},{"location":"#assumptions","text":"This documentation assumes the following: You have a working OPNsense firewall. You have a working Splunk environment. Basic understanding of Splunk and OPNsense.","title":"Assumptions"},{"location":"#about","text":"Info Description Version 1.5.1 - Splunkbase | GitHub CIM 4.x Vendor Product Version OPNsense\u00ae 22.x Get Started","title":"About"},{"location":"getting-started/configure-enrichment/","text":"Configure Enrichment \u00b6 Optional Step Mapping interfaces to their names can help in being able to quickly identify them in Splunk (i.e. vmx0 -> LAN ). This step can be skipped if enrichment is not required. The steps to setup enrichment for this add-on utilize Splunk Lookups. For more information on lookups see Splunk Docs: About lookups . Steps to configure enrichment: Create a CSV Lookup . Create a Lookup Definition . Create an Automatic Lookup Tip To get a full list of interfaces being used in OPNsense: From the OPNsense UI, navigate to Interfaces > Assignments. Create a CSV Lookup \u00b6 Method 1 - Use the Lookup Editor \u00b6 Recommended The lookup editor may be the easiest way to create and mange lookups in Splunk. You can download and install the Lookup Editor from Splunkbase: Lookup Editor . Once installed, the lookup editor can be used to create a new CSV lookup. Open the Lookup Editor in Splunk Web. Click \"Create a New Lookup\" > CSV lookup. Give the lookup a descriptive name (i.e. opn_interfaces.csv) . Choose which App context this lookup will be stored in (i.e. Search & Reporting) . Leave the \"User-only\" box uncheked . This will give the lookup the global scope permissions it needs. Create column headers (row 1). These headers will be referenced later. Populate the remaing rows with the interface name mappings. Example host interface interface_name opnsense-01 em0 LAN opnsense-01 em1 WAN opnsense-01 vmx1 IOT opnsense-01 wg0 WIREGUARD opnsense-02 vmx1 LAN opnsense-02 vmx2 WAN After saving, move to Create a Lookup Definition . Method 2 - Create and Upload a new CSV file \u00b6 A lookup file can be created outside of Splunk and then uploaded via the web interface. Use an editor to create a file in CSV format. Create column headers (row 1). These headers will be referenced later. Populate the remaing rows with the interface name mappings. Example opn_interfaces.csv host,interface,interface_name opnsense-01,em0,LAN opnsense-01,em1,WAN opnsense-01,vmx1,IOT opnsense-01,wg0,WIREGUARD opnsense-02,vmx1,LAN opnsense-02,vmx2,WAN Be sure to save the file with a .csv extension. Open Splunk Web. Navigate to Settings > Lookups > Lookup table files (click \"+ Add new\") Select the Destination App (i.e. Search & Reporting) . Upload the file. Provide the Destination filename. This can be the same name as the one created (i.e. opn_interfaces.csv) . Once saved, Navigate back to Settings > Lookups > Lookup table files, if you are not already there. Search for the name of the file you just uploaded. Modify the permissions for the file by clicking \"Permissions.\" Select \"All apps (system)\" from the two radio options. Check \"Read\" permissions for Everyone. Write permissions can be given as needed (typically set to admin & power). After saving, move to Create a Lookup Definition . Create a Lookup Definition \u00b6 After the CSV lookup has been created, a lookup definition needs to be created. In Splunk Web, Navigate to Settings > Lookups > Lookup definitions (click \"+ Add new\"). Choose a destination app, or leave as default. Give the lookup a name (i.e. opn_interfaces) Select the previously created CSV lookup from the dropdown. Click the \"Advanced\" checkbox. Click the \"Case Sensitive Match\" checkbox to disable case sensitive matching. Once saved, Navigate back to Settings > Lookups > Lookup definitions. Search for the name of the lookup definition you just created. Modify the permissions for the file by clicking \"Permissions.\" Select \"All apps (system)\" from the two radio options. Check \"Read\" permissions for Everyone. Write permissions can be given as needed (typically set to admin & power). After saving, move on to Create Automatic Lookup Create an Automatic Lookup \u00b6 After the Lookup definition has been created, an automatic lookup has to be configured for automatic enrichment. In Splunk Web, Navigate to Settings > Lookups > Automatic lookups (click \"+ Add new\"). Choose a destination app, or leave as default. Give the lookup a name (i.e. opn_interfaces_auto_lookup) Select the previously created lookup definition from the dropdown. For the \"Apply to\" field, select sourcetype and type opnsense:filterlog . For the input fields, first specify the interface field from the created lookup. Then type dest_int for the second field. Example field_from_lookup = dest_int interface = dest_int For the next input field, set host equal to a blank field. There is no need to rename this field. Example host = For the output fields, first specify the interface name field from the created lookup. Then type dest_int_name for the second field. Example field_from_lookup = dest_int_name interface_name = dest_int_name Once saved, Navigate back to Settings > Lookups > Automatic lookups. Search for the name of the automatic lookup you just created. Modify the permissions for the file by clicking \"Permissions.\" Select \"All apps (system)\" from the two radio options. Check \"Read\" permissions for Everyone. Write permissions can be given as needed (typically set to admin & power). Click Save.","title":"Configure Enrichment"},{"location":"getting-started/configure-enrichment/#configure-enrichment","text":"Optional Step Mapping interfaces to their names can help in being able to quickly identify them in Splunk (i.e. vmx0 -> LAN ). This step can be skipped if enrichment is not required. The steps to setup enrichment for this add-on utilize Splunk Lookups. For more information on lookups see Splunk Docs: About lookups . Steps to configure enrichment: Create a CSV Lookup . Create a Lookup Definition . Create an Automatic Lookup Tip To get a full list of interfaces being used in OPNsense: From the OPNsense UI, navigate to Interfaces > Assignments.","title":"Configure Enrichment"},{"location":"getting-started/configure-enrichment/#create-a-csv-lookup","text":"","title":"Create a CSV Lookup"},{"location":"getting-started/configure-enrichment/#method-1-use-the-lookup-editor","text":"Recommended The lookup editor may be the easiest way to create and mange lookups in Splunk. You can download and install the Lookup Editor from Splunkbase: Lookup Editor . Once installed, the lookup editor can be used to create a new CSV lookup. Open the Lookup Editor in Splunk Web. Click \"Create a New Lookup\" > CSV lookup. Give the lookup a descriptive name (i.e. opn_interfaces.csv) . Choose which App context this lookup will be stored in (i.e. Search & Reporting) . Leave the \"User-only\" box uncheked . This will give the lookup the global scope permissions it needs. Create column headers (row 1). These headers will be referenced later. Populate the remaing rows with the interface name mappings. Example host interface interface_name opnsense-01 em0 LAN opnsense-01 em1 WAN opnsense-01 vmx1 IOT opnsense-01 wg0 WIREGUARD opnsense-02 vmx1 LAN opnsense-02 vmx2 WAN After saving, move to Create a Lookup Definition .","title":"Method 1 - Use the Lookup Editor"},{"location":"getting-started/configure-enrichment/#method-2-create-and-upload-a-new-csv-file","text":"A lookup file can be created outside of Splunk and then uploaded via the web interface. Use an editor to create a file in CSV format. Create column headers (row 1). These headers will be referenced later. Populate the remaing rows with the interface name mappings. Example opn_interfaces.csv host,interface,interface_name opnsense-01,em0,LAN opnsense-01,em1,WAN opnsense-01,vmx1,IOT opnsense-01,wg0,WIREGUARD opnsense-02,vmx1,LAN opnsense-02,vmx2,WAN Be sure to save the file with a .csv extension. Open Splunk Web. Navigate to Settings > Lookups > Lookup table files (click \"+ Add new\") Select the Destination App (i.e. Search & Reporting) . Upload the file. Provide the Destination filename. This can be the same name as the one created (i.e. opn_interfaces.csv) . Once saved, Navigate back to Settings > Lookups > Lookup table files, if you are not already there. Search for the name of the file you just uploaded. Modify the permissions for the file by clicking \"Permissions.\" Select \"All apps (system)\" from the two radio options. Check \"Read\" permissions for Everyone. Write permissions can be given as needed (typically set to admin & power). After saving, move to Create a Lookup Definition .","title":"Method 2 - Create and Upload a new CSV file"},{"location":"getting-started/configure-enrichment/#create-a-lookup-definition","text":"After the CSV lookup has been created, a lookup definition needs to be created. In Splunk Web, Navigate to Settings > Lookups > Lookup definitions (click \"+ Add new\"). Choose a destination app, or leave as default. Give the lookup a name (i.e. opn_interfaces) Select the previously created CSV lookup from the dropdown. Click the \"Advanced\" checkbox. Click the \"Case Sensitive Match\" checkbox to disable case sensitive matching. Once saved, Navigate back to Settings > Lookups > Lookup definitions. Search for the name of the lookup definition you just created. Modify the permissions for the file by clicking \"Permissions.\" Select \"All apps (system)\" from the two radio options. Check \"Read\" permissions for Everyone. Write permissions can be given as needed (typically set to admin & power). After saving, move on to Create Automatic Lookup","title":"Create a Lookup Definition"},{"location":"getting-started/configure-enrichment/#create-an-automatic-lookup","text":"After the Lookup definition has been created, an automatic lookup has to be configured for automatic enrichment. In Splunk Web, Navigate to Settings > Lookups > Automatic lookups (click \"+ Add new\"). Choose a destination app, or leave as default. Give the lookup a name (i.e. opn_interfaces_auto_lookup) Select the previously created lookup definition from the dropdown. For the \"Apply to\" field, select sourcetype and type opnsense:filterlog . For the input fields, first specify the interface field from the created lookup. Then type dest_int for the second field. Example field_from_lookup = dest_int interface = dest_int For the next input field, set host equal to a blank field. There is no need to rename this field. Example host = For the output fields, first specify the interface name field from the created lookup. Then type dest_int_name for the second field. Example field_from_lookup = dest_int_name interface_name = dest_int_name Once saved, Navigate back to Settings > Lookups > Automatic lookups. Search for the name of the automatic lookup you just created. Modify the permissions for the file by clicking \"Permissions.\" Select \"All apps (system)\" from the two radio options. Check \"Read\" permissions for Everyone. Write permissions can be given as needed (typically set to admin & power). Click Save.","title":"Create an Automatic Lookup"},{"location":"getting-started/logging-architecture/","text":"Log Collection Architecture \u00b6 The following diagram shows a basic logging architecture to get data from the OPNsense firewall to Splunk. For more information on installation see Where to install . Syslog Server Considerations \u00b6 It is recommended to use an intermediate syslog server with a Splunk Universal Forwarder installed. This allows for reliable and secure data collection in Splunk. For more information on syslog and Splunk, see the (SYSLOG) Syslog Data Collection section of the Splunk Validated Architectures white paper. If you want to simply your deployment you can choose to send syslog data directly to Splunk. For more information on collecting data from TCP/UDP ports see Splunk Docs: Get data from TCP and UDP ports . This documentation will provide steps on configuring inputs from data being collected by a syslog server. See the Guide: Syslog for onboarding data via rsyslog/syslog-ng in this documentation. Single instance deployment \u00b6 When you install this add-on to a single Splunk Enterprise instance, that instance serves as both search head and indexer and provides both search and storage capability. A single instance deployment can support a few users running concurrent searches, which is ideal for a small test environment. Distributed deployment \u00b6 Distributed deployments consist of separate instances for indexers and search heads. In both single instance and distributed deployments using a universal forwarder to get data in is recommended.","title":"Logging Architecture"},{"location":"getting-started/logging-architecture/#log-collection-architecture","text":"The following diagram shows a basic logging architecture to get data from the OPNsense firewall to Splunk. For more information on installation see Where to install .","title":"Log Collection Architecture"},{"location":"getting-started/logging-architecture/#syslog-server-considerations","text":"It is recommended to use an intermediate syslog server with a Splunk Universal Forwarder installed. This allows for reliable and secure data collection in Splunk. For more information on syslog and Splunk, see the (SYSLOG) Syslog Data Collection section of the Splunk Validated Architectures white paper. If you want to simply your deployment you can choose to send syslog data directly to Splunk. For more information on collecting data from TCP/UDP ports see Splunk Docs: Get data from TCP and UDP ports . This documentation will provide steps on configuring inputs from data being collected by a syslog server. See the Guide: Syslog for onboarding data via rsyslog/syslog-ng in this documentation.","title":"Syslog Server Considerations"},{"location":"getting-started/logging-architecture/#single-instance-deployment","text":"When you install this add-on to a single Splunk Enterprise instance, that instance serves as both search head and indexer and provides both search and storage capability. A single instance deployment can support a few users running concurrent searches, which is ideal for a small test environment.","title":"Single instance deployment"},{"location":"getting-started/logging-architecture/#distributed-deployment","text":"Distributed deployments consist of separate instances for indexers and search heads. In both single instance and distributed deployments using a universal forwarder to get data in is recommended.","title":"Distributed deployment"},{"location":"getting-started/where-to-install/","text":"Where to Install \u00b6 For detailed information on where to install Splunk Apps/add-ons, including best practices, can be found at Splunk Docs: About Installing Splunk add-ons Standalone Deployments \u00b6 Install this add-on to the single instance. For more information see Splunk Docs: Install add-on in a single-instance Splunk deployment Distributed Deployments \u00b6 Splunk Instance type Supported Required Comments Search Heads Yes Yes Install this add-on to all search heads. Indexers Yes Conditional Not required if heavy forwarders are used to collect data, required if not. Heavy Forwarders Yes Conditional Required, if HFs are used to collect this data source. Universal Forwarders Yes Not required The add-on includes an inputs.conf file that is disabled by default. This can be used to create an input on the forwarder if enabled. The installation steps for deploying Apps/add-ons in a distributed environment can be found at Splunk Docs: Install an add-on in a distributed Splunk deployment Distributed Deployment Compatibility \u00b6 Distributed deployment feature Supported Comments Search Head Clusters Yes You can install this add-on to a search head cluster. Indexer Clusters Yes You can install this add-on to a indexer cluster. Deployment Server Yes You can use a deployment server to push this add-on to Splunk Universal Forwarders. * For more information, see Splunk's documentation on installing Add-ons.","title":"Where to Install"},{"location":"getting-started/where-to-install/#where-to-install","text":"For detailed information on where to install Splunk Apps/add-ons, including best practices, can be found at Splunk Docs: About Installing Splunk add-ons","title":"Where to Install"},{"location":"getting-started/where-to-install/#standalone-deployments","text":"Install this add-on to the single instance. For more information see Splunk Docs: Install add-on in a single-instance Splunk deployment","title":"Standalone Deployments"},{"location":"getting-started/where-to-install/#distributed-deployments","text":"Splunk Instance type Supported Required Comments Search Heads Yes Yes Install this add-on to all search heads. Indexers Yes Conditional Not required if heavy forwarders are used to collect data, required if not. Heavy Forwarders Yes Conditional Required, if HFs are used to collect this data source. Universal Forwarders Yes Not required The add-on includes an inputs.conf file that is disabled by default. This can be used to create an input on the forwarder if enabled. The installation steps for deploying Apps/add-ons in a distributed environment can be found at Splunk Docs: Install an add-on in a distributed Splunk deployment","title":"Distributed Deployments"},{"location":"getting-started/where-to-install/#distributed-deployment-compatibility","text":"Distributed deployment feature Supported Comments Search Head Clusters Yes You can install this add-on to a search head cluster. Indexer Clusters Yes You can install this add-on to a indexer cluster. Deployment Server Yes You can use a deployment server to push this add-on to Splunk Universal Forwarders. * For more information, see Splunk's documentation on installing Add-ons.","title":"Distributed Deployment Compatibility"},{"location":"getting-started/configure-inputs/configure-inputs/","text":"Configure Splunk Input \u00b6 Objective : Set the sourcetype to opnsense in the inputs.conf file on the forwarder. Create new indexes \u00b6 Optional If you do not wish to create a new index, skip to Splunk Universal Forwarder Configuration . Splunk stores data in indexes. This add-on may be configured to send to a custom event index instead of the default index, main. For more information and steps to create a new index, see Splunk Docs: Create events indexes . Purpose for creating new indexes \u00b6 The out of the box Splunk configuration stores all data in the default index, main. It is encouraged to create a new index to ensure optimal performance, for setting retention policies, and for providing stricter access controls. For more information about how Splunk indexes work with add-ons, see Splunk Docs: Add-ons and indexes . OPNsense has a variety of data sources that can be broken up in to separate indexes. For more information and some examples on creating and utilizing indexes see the Guide: Index Utilization in this documentation. Splunk Universal Forwarder Configuration \u00b6 Download the latest Splunk Universal Forwarder (UF) appropriate for your server. Don't have a syslog server setup yet? See Syslog Setup for guided steps. If you don't want to use a syslog server see Splunk Docs: Get data from TCP and UDP ports and skip these steps. Install the UF according to Splunk Docs: Install the Universal Forwarder on the server designated as your syslog server. Once installed the configurations can be made. The following is a sample inputs.conf that can be pushed using a deployment server or configured on the UF itself. inputs.conf [monitor:///var/log/remote/opnsense] disabled = 0 host_segment = 5 sourcetype = opnsense # optionally specify an index, if configured. index = netfw Push the configuration to the forwarder, if using a deployment server, or restart the UF if configuring on the UF itself. Verify \u00b6 Verify the setup has completed successfully by navigating to Splunk web and running a search similar to the following: index = <chosen index> sourcetype = opnsense* If you see data then you are all set! Proceed to Configuring Modular Inputs or start visualizing your data by downloading and installing the OPNsense App for Splunk . If you are not seeing your data, see Troubleshooting Monitoring Inputs .","title":"Configure Universal Forwarder"},{"location":"getting-started/configure-inputs/configure-inputs/#configure-splunk-input","text":"Objective : Set the sourcetype to opnsense in the inputs.conf file on the forwarder.","title":"Configure Splunk Input"},{"location":"getting-started/configure-inputs/configure-inputs/#create-new-indexes","text":"Optional If you do not wish to create a new index, skip to Splunk Universal Forwarder Configuration . Splunk stores data in indexes. This add-on may be configured to send to a custom event index instead of the default index, main. For more information and steps to create a new index, see Splunk Docs: Create events indexes .","title":"Create new indexes"},{"location":"getting-started/configure-inputs/configure-inputs/#purpose-for-creating-new-indexes","text":"The out of the box Splunk configuration stores all data in the default index, main. It is encouraged to create a new index to ensure optimal performance, for setting retention policies, and for providing stricter access controls. For more information about how Splunk indexes work with add-ons, see Splunk Docs: Add-ons and indexes . OPNsense has a variety of data sources that can be broken up in to separate indexes. For more information and some examples on creating and utilizing indexes see the Guide: Index Utilization in this documentation.","title":"Purpose for creating new indexes"},{"location":"getting-started/configure-inputs/configure-inputs/#splunk-universal-forwarder-configuration","text":"Download the latest Splunk Universal Forwarder (UF) appropriate for your server. Don't have a syslog server setup yet? See Syslog Setup for guided steps. If you don't want to use a syslog server see Splunk Docs: Get data from TCP and UDP ports and skip these steps. Install the UF according to Splunk Docs: Install the Universal Forwarder on the server designated as your syslog server. Once installed the configurations can be made. The following is a sample inputs.conf that can be pushed using a deployment server or configured on the UF itself. inputs.conf [monitor:///var/log/remote/opnsense] disabled = 0 host_segment = 5 sourcetype = opnsense # optionally specify an index, if configured. index = netfw Push the configuration to the forwarder, if using a deployment server, or restart the UF if configuring on the UF itself.","title":"Splunk Universal Forwarder Configuration"},{"location":"getting-started/configure-inputs/configure-inputs/#verify","text":"Verify the setup has completed successfully by navigating to Splunk web and running a search similar to the following: index = <chosen index> sourcetype = opnsense* If you see data then you are all set! Proceed to Configuring Modular Inputs or start visualizing your data by downloading and installing the OPNsense App for Splunk . If you are not seeing your data, see Troubleshooting Monitoring Inputs .","title":"Verify"},{"location":"getting-started/configure-inputs/configure-modinput/","text":"Configure Modular Input \u00b6 The TA-opnsense modular input will interact with the OPNsense API using GET requests. This allows for system information to be returned to enrich the already ingested Splunk data. For more information on what data is collected by this modular input see Reference: Modular Input in this documentation. Overview \u00b6 Perform prerequisites Create Account Create Input Tested Versions OPNsense v21.7 Add-on Version 1.4.0 Prerequisites \u00b6 Obtain API Credentials . FQDN/IP of the OPNsense instance (multiple instances may be setup through the interface). (optional) CA Certificate for OPNsense instance . Splunk must be able to communicate to the firewall directly through the web port (default 443/tcp) or through a proxy. Obtain API Credentials \u00b6 Log in to the OPNsense web interface. Navigate to System > Access > Users. Create a new user or edit an existing user. Scroll down to the API keys section, click the \"+\" to create new API credentials. This downloads an \"apikey.txt\" file containing the credentials for the API. These will be used in later steps . Obtain CA Certificate \u00b6 Optional The Certificate Authority ( CA ) certificate can be used to verify authenticity of the device you are connecting to. Log in to the OPNsense web interface. Navigate to System > Trust > Authorities. Not Seeing any Certificates? If no certificates show up in this view, this could mean that you are using the default self-signed Web certificate from OPNsense. If this is the case, skip these steps and ensue the \"Verify Certificate\" checkbox is not checked when setting up the modular input. For better security, it is recommended to create a new certificate for the OPNsense web interface (see OPNsense Documentation for more information). Export the CA cert of the Authority being used for the web interface. Place the CA Certificate into $SPLUNK_HOME/etc/auth . It may be easier to create a new directory to keep this certificate separate (i.e. $SPLUNK_HOME/etc/auth/opnsense_certs ) . Create Account \u00b6 At least one account is needed for the modular input to work. Verify Prerequisites have been completed before proceeding. Log in to the Splunk web interface. Navigate to the OPNsense Add-on for Splunk > Configuration (Tab). Not seeing the OPNsense Add-on? The OPNsense Add-on for Splunk must be set to visible in order to configure the modular input. In Splunk web, navigate to the \"Manage Apps\" view by clicking the gear icon on the Launcher page or click \"Manage Apps\" from the \"Apps\" dropdown next to the Splunk logo on the top left of the screen. In the app list search for \"OPNsense Add-on\" and click \"Edit properties\" on the right side. Ensure \"Visible\" is set to Yes and save. Add a new Account. Enter a name for the account. Enter the API credentials previously created. Enter the IP/FQDN of the OPNsense instance. If different from default port of 443, enter the port number being used. (Optional) Enter the certificate path relative to $SPLUNK_HOME/etc/auth or as an absolute path. Example relative path : opnsense_certs/OPNsense.crt absolute path : /opt/splunk/etc/auth/opnsense_certs/OPNsense.crt Uncheck the box if you are not using a certificate to verify. Click add. (optional) Configure proxy. (optional) Set logging level. Proceed to create an input . Create Input \u00b6 An account is needed before proceeding. Navigate to the Input tab. Click \"Create New Input.\" Enter a unique name. Set an interval to run in seconds or a valid cron schedule. Select an index. Select the correct account credentials for the input. Click add. Verify \u00b6 Once completed the modular input will immediately run. To verify open up a search and run a similar query: index = <your index> sourcetype = opnsense:system If data does not appear within a few minutes, see Troubleshooting Modular Inputs .","title":"Configure Modular Input"},{"location":"getting-started/configure-inputs/configure-modinput/#configure-modular-input","text":"The TA-opnsense modular input will interact with the OPNsense API using GET requests. This allows for system information to be returned to enrich the already ingested Splunk data. For more information on what data is collected by this modular input see Reference: Modular Input in this documentation.","title":"Configure Modular Input"},{"location":"getting-started/configure-inputs/configure-modinput/#overview","text":"Perform prerequisites Create Account Create Input Tested Versions OPNsense v21.7 Add-on Version 1.4.0","title":"Overview"},{"location":"getting-started/configure-inputs/configure-modinput/#prerequisites","text":"Obtain API Credentials . FQDN/IP of the OPNsense instance (multiple instances may be setup through the interface). (optional) CA Certificate for OPNsense instance . Splunk must be able to communicate to the firewall directly through the web port (default 443/tcp) or through a proxy.","title":"Prerequisites"},{"location":"getting-started/configure-inputs/configure-modinput/#obtain-api-credentials","text":"Log in to the OPNsense web interface. Navigate to System > Access > Users. Create a new user or edit an existing user. Scroll down to the API keys section, click the \"+\" to create new API credentials. This downloads an \"apikey.txt\" file containing the credentials for the API. These will be used in later steps .","title":"Obtain API Credentials"},{"location":"getting-started/configure-inputs/configure-modinput/#obtain-ca-certificate","text":"Optional The Certificate Authority ( CA ) certificate can be used to verify authenticity of the device you are connecting to. Log in to the OPNsense web interface. Navigate to System > Trust > Authorities. Not Seeing any Certificates? If no certificates show up in this view, this could mean that you are using the default self-signed Web certificate from OPNsense. If this is the case, skip these steps and ensue the \"Verify Certificate\" checkbox is not checked when setting up the modular input. For better security, it is recommended to create a new certificate for the OPNsense web interface (see OPNsense Documentation for more information). Export the CA cert of the Authority being used for the web interface. Place the CA Certificate into $SPLUNK_HOME/etc/auth . It may be easier to create a new directory to keep this certificate separate (i.e. $SPLUNK_HOME/etc/auth/opnsense_certs ) .","title":"Obtain CA Certificate"},{"location":"getting-started/configure-inputs/configure-modinput/#create-account","text":"At least one account is needed for the modular input to work. Verify Prerequisites have been completed before proceeding. Log in to the Splunk web interface. Navigate to the OPNsense Add-on for Splunk > Configuration (Tab). Not seeing the OPNsense Add-on? The OPNsense Add-on for Splunk must be set to visible in order to configure the modular input. In Splunk web, navigate to the \"Manage Apps\" view by clicking the gear icon on the Launcher page or click \"Manage Apps\" from the \"Apps\" dropdown next to the Splunk logo on the top left of the screen. In the app list search for \"OPNsense Add-on\" and click \"Edit properties\" on the right side. Ensure \"Visible\" is set to Yes and save. Add a new Account. Enter a name for the account. Enter the API credentials previously created. Enter the IP/FQDN of the OPNsense instance. If different from default port of 443, enter the port number being used. (Optional) Enter the certificate path relative to $SPLUNK_HOME/etc/auth or as an absolute path. Example relative path : opnsense_certs/OPNsense.crt absolute path : /opt/splunk/etc/auth/opnsense_certs/OPNsense.crt Uncheck the box if you are not using a certificate to verify. Click add. (optional) Configure proxy. (optional) Set logging level. Proceed to create an input .","title":"Create Account"},{"location":"getting-started/configure-inputs/configure-modinput/#create-input","text":"An account is needed before proceeding. Navigate to the Input tab. Click \"Create New Input.\" Enter a unique name. Set an interval to run in seconds or a valid cron schedule. Select an index. Select the correct account credentials for the input. Click add.","title":"Create Input"},{"location":"getting-started/configure-inputs/configure-modinput/#verify","text":"Once completed the modular input will immediately run. To verify open up a search and run a similar query: index = <your index> sourcetype = opnsense:system If data does not appear within a few minutes, see Troubleshooting Modular Inputs .","title":"Verify"},{"location":"getting-started/troubleshooting/troubleshoot-inputs/","text":"Troubleshoot Monitoring Inputs \u00b6 There is a variety of issues when getting new data into Splunk. Below are a few of the most common issues: Issue Description Solution Splunk cannot read the file If the user running Splunk (default is splunk ) cannot read the contents of the file, the data will not be sent to Splunk. log in as the Splunk user and verify the contents can be read. If not, update the permissions of the file to allow read access to the Splunk user. Incorrect timestamps Having the incorrect time setup on either the Splunk instance or syslog server may result in not ingesting the data. In Splunk web, try switching the time range to \"All Time\" when looking for the data. If the data is found and the incorrect time is observed, update the servers to the correct time and consider utilizing a NTP server for proper time synchronization. Splunk Forwarder communication It is possible that the Splunk Universal Forwarder does not have a connection to the Splunk instance. Verify connection by running the following command on the universal forwarder: $SPLUNK_HOME/bin/splunk list forward-server . $SPLUNK_HOME is the installation directory. The output from this command will show active/inactive connections to the Splunk Instance. Alternatively the internal logs can be searched in Splunk Web. Run the following command on the search head: index=_internal source=*metrics.log* tcpin_connections | stats count by sourceIp . The output of this search will show a list of sources connecting to the Splunk Instance. For more troubleshooting steps, see Splunk Docs: Troubleshooting Data .","title":"Troubleshoot Monitoring Inputs"},{"location":"getting-started/troubleshooting/troubleshoot-inputs/#troubleshoot-monitoring-inputs","text":"There is a variety of issues when getting new data into Splunk. Below are a few of the most common issues: Issue Description Solution Splunk cannot read the file If the user running Splunk (default is splunk ) cannot read the contents of the file, the data will not be sent to Splunk. log in as the Splunk user and verify the contents can be read. If not, update the permissions of the file to allow read access to the Splunk user. Incorrect timestamps Having the incorrect time setup on either the Splunk instance or syslog server may result in not ingesting the data. In Splunk web, try switching the time range to \"All Time\" when looking for the data. If the data is found and the incorrect time is observed, update the servers to the correct time and consider utilizing a NTP server for proper time synchronization. Splunk Forwarder communication It is possible that the Splunk Universal Forwarder does not have a connection to the Splunk instance. Verify connection by running the following command on the universal forwarder: $SPLUNK_HOME/bin/splunk list forward-server . $SPLUNK_HOME is the installation directory. The output from this command will show active/inactive connections to the Splunk Instance. Alternatively the internal logs can be searched in Splunk Web. Run the following command on the search head: index=_internal source=*metrics.log* tcpin_connections | stats count by sourceIp . The output of this search will show a list of sources connecting to the Splunk Instance. For more troubleshooting steps, see Splunk Docs: Troubleshooting Data .","title":"Troubleshoot Monitoring Inputs"},{"location":"getting-started/troubleshooting/troubleshoot-modinputs/","text":"Modular Input Troubleshooting \u00b6 If no logs appear in the index you specified after configuring the input, use the following to troubleshoot. Set the logging mode to \"Debug\" on the Configuration Tab. Search the internal logs for errors: index = _internal sourcetype = taopnsense:log","title":"Troubleshoot Modular Inputs"},{"location":"getting-started/troubleshooting/troubleshoot-modinputs/#modular-input-troubleshooting","text":"If no logs appear in the index you specified after configuring the input, use the following to troubleshoot. Set the logging mode to \"Debug\" on the Configuration Tab. Search the internal logs for errors: index = _internal sourcetype = taopnsense:log","title":"Modular Input Troubleshooting"},{"location":"guides/guide-collect-netflows/","text":"Collect Netflows from OPNsense \u00b6 Todo Collect netflows using Splunk stream","title":"Collect Netflows from OPNsense"},{"location":"guides/guide-collect-netflows/#collect-netflows-from-opnsense","text":"Todo Collect netflows using Splunk stream","title":"Collect Netflows from OPNsense"},{"location":"guides/guide-index-utilization/","text":"Index Utilization Guide \u00b6 The out of the box Splunk configuration stores all data in the default index, main. It is encouraged to create a new index to ensure optimal performance, for setting retention policies, and for providing stricter access controls. For more information about how Splunk indexes work with add-ons, see Splunk Docs: Add-ons and indexes . OPNsense has a variety of data sources that can be broken up in to separate indexes. The below table is an example of the data can be split up in to different indexes. Index Sourcetype(s) netauth opnsense:access netdhcp opnsense:dhcpd netfw opnsense:filterlog netfwsystem opnsense, opnsense:cron, opnsense:system, opnsense:syslog netids opnsense:suricata, opnsense:suricata:json netproxy opnsense:squid, opnsense:lighttpd New indexes can be created through configuration files or through Splunk web. See Splunk Docs: Create events indexes for more information. This guide walks through the following steps to utilize created indexes: Set index at input time Change index at index time Set index at input time \u00b6 Setting the index at input time can save some resources on the indexers. This requires a more advanced syslog configuration to ensure the files are properly broken up by data type. If you followed the the guide for Syslog Setup then you should have multiple files broken up by the data source (i.e. filterlog, suricata, dhcpd) . We will create inputs to assign sourcetypes based on these files. Configure inputs \u00b6 inputs.conf example inputs.conf [monitor:///var/log/remote/opnsense/*/filterlog.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netfw [monitor:///var/log/remote/opnsense/*/access.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netauth [monitor:///var/log/remote/opnsense/*/dhcpd.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netdhcp [monitor:///var/log/remote/opnsense/*/suricata.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netids [monitor:///var/log/remote/opnsense/*/squid.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netproxy [monitor:///var/log/remote/opnsense/*/lighttpd.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netproxy [monitor:///var/log/remote/opnsense/*/openvpn.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netvpn [monitor:///var/log/remote/opnsense/*/cron.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netfwsystem [monitor:///var/log/remote/opnsense/*/catchall.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netfwsystem Change index at index time \u00b6 The data can be changed to the correct index during index time operations. In this example INGEST_EVAL will be used. For more information about INGEST_EVAL see Splunk Docs: Ingest Eval . These steps assume the data onboarding process, including index creation, has been completed and data is ready to be collected in Splunk. The following changes will need to be made on the indexers. Open the configuration file located at $SPLUNK_HOME/etc/apps/TA-opnsense/local/props.conf. This file and directory may have to be created. Create a transforms statement for the opnsense sourcetype. This should be the sourcetype set in the inputs.conf file (see Configure Inputs ) for more information. $SPLUNK_HOME/etc/apps/TA-opnsense/localprops.conf [opnsense] TRANSFORMS-z_opn_change_index = opn_change_index Notice the \"z\" at the beginning of the name (TRANSFORMS- z _opn_change_index). This will cause this transform to run later in the index operations. This is important because this add-on utilizes a sourcetype transforms that must run before this transform. Now a transform will need to be created at $SPLUNK_HOME/etc/apps/TA-opnsense/local/transforms.conf. This file may have to be created. Create an INGEST_EVAL statement changing the data to the correct index based off the sourcetype. $SPLUNK_HOME/etc/apps/TA-opnsense/local/transforms.conf [opn_change_index] # this name MUST match the name in props.conf INGEST_EVAL = index=case(match(sourcetype, \"dhcpd\"), \"netdhcp\", match(sourcetype, \"lighttpd|squid\"), \"netproxy\", match(sourcetype, \"access\"), \"netauth\", match(sourcetype, \"suricata\"), \"netids\" , match(sourcetype, \"cron|system|syslog|opnsense$\"), \"netfwsystem\" , true(), index) This uses a case statement to perform a regex match on the sourcetype to then change to the appropriate index. Note that the match statement does not have to be used here and a simple sourcetype==\"opnsense:dhcpd\" statement could be used. After you finish making the appropriate changes to the INGEST_EVAL command, splunk will need to be restarted for the changes to take affect. Verify by searching the expected indexes for the data. Troubleshoot \u00b6 Ensure that you ingest_eval command works by pasting it in to Splunk web using an eval statement replacing index with another name. Example index = * sourcetype = opnsense* | eval test = case ( match ( sourcetype, \"dhcpd\" ) , \"netdhcp\" , match ( sourcetype, \"lighttpd|squid\" ) , \"netproxy\" , match ( sourcetype, \"access\" ) , \"netauth\" , match ( sourcetype, \"suricata\" ) , \"netids\" , match ( sourcetype, \"cron|system|syslog|opnsense $ \" ) , \"netfwsystem\" , true () , index ) | stats count by sourcetype, test If there are no errors and the command works as expected, be sure that splunk was restarted. $SPLUNK_HOME/bin/splunk btool check can also be run to see if there are any errors in the configuration file. If there are no errors, check the spelling in the props.conf and transforms.conf for the name given. The name set in props.conf must match the stanza in transforms.conf.","title":"Index Utilization"},{"location":"guides/guide-index-utilization/#index-utilization-guide","text":"The out of the box Splunk configuration stores all data in the default index, main. It is encouraged to create a new index to ensure optimal performance, for setting retention policies, and for providing stricter access controls. For more information about how Splunk indexes work with add-ons, see Splunk Docs: Add-ons and indexes . OPNsense has a variety of data sources that can be broken up in to separate indexes. The below table is an example of the data can be split up in to different indexes. Index Sourcetype(s) netauth opnsense:access netdhcp opnsense:dhcpd netfw opnsense:filterlog netfwsystem opnsense, opnsense:cron, opnsense:system, opnsense:syslog netids opnsense:suricata, opnsense:suricata:json netproxy opnsense:squid, opnsense:lighttpd New indexes can be created through configuration files or through Splunk web. See Splunk Docs: Create events indexes for more information. This guide walks through the following steps to utilize created indexes: Set index at input time Change index at index time","title":"Index Utilization Guide"},{"location":"guides/guide-index-utilization/#set-index-at-input-time","text":"Setting the index at input time can save some resources on the indexers. This requires a more advanced syslog configuration to ensure the files are properly broken up by data type. If you followed the the guide for Syslog Setup then you should have multiple files broken up by the data source (i.e. filterlog, suricata, dhcpd) . We will create inputs to assign sourcetypes based on these files.","title":"Set index at input time"},{"location":"guides/guide-index-utilization/#configure-inputs","text":"inputs.conf example inputs.conf [monitor:///var/log/remote/opnsense/*/filterlog.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netfw [monitor:///var/log/remote/opnsense/*/access.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netauth [monitor:///var/log/remote/opnsense/*/dhcpd.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netdhcp [monitor:///var/log/remote/opnsense/*/suricata.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netids [monitor:///var/log/remote/opnsense/*/squid.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netproxy [monitor:///var/log/remote/opnsense/*/lighttpd.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netproxy [monitor:///var/log/remote/opnsense/*/openvpn.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netvpn [monitor:///var/log/remote/opnsense/*/cron.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netfwsystem [monitor:///var/log/remote/opnsense/*/catchall.log] disabled = 0 host_segment = 5 sourcetype = opnsense index = netfwsystem","title":"Configure inputs"},{"location":"guides/guide-index-utilization/#change-index-at-index-time","text":"The data can be changed to the correct index during index time operations. In this example INGEST_EVAL will be used. For more information about INGEST_EVAL see Splunk Docs: Ingest Eval . These steps assume the data onboarding process, including index creation, has been completed and data is ready to be collected in Splunk. The following changes will need to be made on the indexers. Open the configuration file located at $SPLUNK_HOME/etc/apps/TA-opnsense/local/props.conf. This file and directory may have to be created. Create a transforms statement for the opnsense sourcetype. This should be the sourcetype set in the inputs.conf file (see Configure Inputs ) for more information. $SPLUNK_HOME/etc/apps/TA-opnsense/localprops.conf [opnsense] TRANSFORMS-z_opn_change_index = opn_change_index Notice the \"z\" at the beginning of the name (TRANSFORMS- z _opn_change_index). This will cause this transform to run later in the index operations. This is important because this add-on utilizes a sourcetype transforms that must run before this transform. Now a transform will need to be created at $SPLUNK_HOME/etc/apps/TA-opnsense/local/transforms.conf. This file may have to be created. Create an INGEST_EVAL statement changing the data to the correct index based off the sourcetype. $SPLUNK_HOME/etc/apps/TA-opnsense/local/transforms.conf [opn_change_index] # this name MUST match the name in props.conf INGEST_EVAL = index=case(match(sourcetype, \"dhcpd\"), \"netdhcp\", match(sourcetype, \"lighttpd|squid\"), \"netproxy\", match(sourcetype, \"access\"), \"netauth\", match(sourcetype, \"suricata\"), \"netids\" , match(sourcetype, \"cron|system|syslog|opnsense$\"), \"netfwsystem\" , true(), index) This uses a case statement to perform a regex match on the sourcetype to then change to the appropriate index. Note that the match statement does not have to be used here and a simple sourcetype==\"opnsense:dhcpd\" statement could be used. After you finish making the appropriate changes to the INGEST_EVAL command, splunk will need to be restarted for the changes to take affect. Verify by searching the expected indexes for the data.","title":"Change index at index time"},{"location":"guides/guide-index-utilization/#troubleshoot","text":"Ensure that you ingest_eval command works by pasting it in to Splunk web using an eval statement replacing index with another name. Example index = * sourcetype = opnsense* | eval test = case ( match ( sourcetype, \"dhcpd\" ) , \"netdhcp\" , match ( sourcetype, \"lighttpd|squid\" ) , \"netproxy\" , match ( sourcetype, \"access\" ) , \"netauth\" , match ( sourcetype, \"suricata\" ) , \"netids\" , match ( sourcetype, \"cron|system|syslog|opnsense $ \" ) , \"netfwsystem\" , true () , index ) | stats count by sourcetype, test If there are no errors and the command works as expected, be sure that splunk was restarted. $SPLUNK_HOME/bin/splunk btool check can also be run to see if there are any errors in the configuration file. If there are no errors, check the spelling in the props.conf and transforms.conf for the name given. The name set in props.conf must match the stanza in transforms.conf.","title":"Troubleshoot"},{"location":"guides/guide-intrusion-detection/","text":"Intrusion Detection Logging Setup \u00b6 This guide assumes that you already have the packaged necessary for the Intrusion detection service. For more information see OPNsense Docs: Intrusion Detection . Log in to OPNsense. Navigate to Services > Intrusion Detection > Administration. Click the \"advanced mode\" toggle. It is recommended to use the eve syslog output setting. This will provide the most verbose output. Additionally, the payload can be logged by checking the \"log package payload\" box. Once you are satisfied with all other settings, click enable and then apply. For more information on all other settings see OPNsense Docs: Intrusion Detection .","title":"Intrusion Detection Logging"},{"location":"guides/guide-intrusion-detection/#intrusion-detection-logging-setup","text":"This guide assumes that you already have the packaged necessary for the Intrusion detection service. For more information see OPNsense Docs: Intrusion Detection . Log in to OPNsense. Navigate to Services > Intrusion Detection > Administration. Click the \"advanced mode\" toggle. It is recommended to use the eve syslog output setting. This will provide the most verbose output. Additionally, the payload can be logged by checking the \"log package payload\" box. Once you are satisfied with all other settings, click enable and then apply. For more information on all other settings see OPNsense Docs: Intrusion Detection .","title":"Intrusion Detection Logging Setup"},{"location":"guides/guide-syslog/","text":"Syslog Guide \u00b6 Sending data to a syslog server where a Splunk forwarder is monitoring the files can improve the data collection to Splunk. A Splunk forwarder automatically load-balances data to all indexers in a distributed environment and can be setup with TLS and other setting to ensure the data transmission is secure and reliable. Utilizing a syslog server will also help prevent gaps in data when Splunk needs to restart for maintenance or unplanned shutdowns. For more information see Splunk answers and Splunk Docs: Forwarder Manual . More information on syslog and Splunk, see the (SYSLOG) Syslog Data Collection section of the Splunk Validated Architectures white paper. The following will walk through an example of setting up syslog using Rsyslog. Syslog-ng example can be found at the below blog posts: High Performance Syslog - Part 1 High Performance Syslog - Part 2 Using Syslong-ng with Splunk Data on-boarding using Rsyslog \u00b6 Rsyslog is a default package on most linux distros. The OPNsense firewall can be setup to send logs via syslog to a configured Rsyslog server for a Splunk Forwarder to monitor. Below is a basic configuration to get started with data on-boarding. Note The following does not reflect rsyslog best practices but could be used as a starting point. Rsyslog Basic Configuration \u00b6 Tested with Rsyslog version: rsyslogd 8.32.0 on RHEL/CentOS/Ubuntu The default rsyslog configuration file is located in /etc/rsyslog.conf . Open the rsyslog configuration file with your favorite text editor. Place the following in the configuration file or uncomment if already present: Load Modules \u00b6 Load in the appropriate modules for TCP/UDP module ( load = \"imudp\" ) # provides UDP syslog reception File Permissions \u00b6 The following sets file permissions to root:splunk . # OMFILE Global Permissions module ( load = \"builtin:omfile\" dirCreateMode = \"0750\" dirOwner = \"root\" dirGroup = \"splunk\" fileCreateMode = \"0640\" fileOwner = \"root\" fileGroup = \"splunk\" ) # Legacy Permissions $umask 0027 $DirCreateMode 0750 $FileCreateMode 0640 $DirGroup splunk $FileGroup splunk Event Format Template \u00b6 The following is a standard example of how to set a template for an event format. This helps to standardize the logs to work better with Splunk. # Event Template template ( name = \"t_default\" type = \"list\" ) { property ( name = \"timestamp\" dateFormat = \"rfc3339\" ) constant ( value = \" \" ) property ( name = \"fromhost\" ) # can also be set to 'hostname' constant ( value = \" \" ) property ( name = \"syslogtag\" ) property ( name = \"msg\" spifno1stsp = \"on\" ) property ( name = \"msg\" droplastlf = \"on\" ) constant ( value = \"\\n\" ) } This will create events similar to the following: 2020 -02-16T22:47:31-00:00 myserver-003 named [ 32422 ] : 136299 10 .0.0.5/48300 reply apps.splunk.com is 52 .41.47.241 Dynamic File Templates \u00b6 Create reusable templates for easy change-management template ( name = \"t_opnsense_filterlog\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/filterlog.log\" ) template ( name = \"t_opnsense_suricata\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/suricata.log\" ) template ( name = \"t_opnsense_openvpn\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/openvpn.log\" ) template ( name = \"t_opnsense_cron\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/cron.log\" ) template ( name = \"t_opnsense_squid\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/squid.log\" ) template ( name = \"t_opnsense_lighttpd\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/lighttpd.log\" ) template ( name = \"t_opnsense_dhcpd\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/dhcpd.log\" ) template ( name = \"t_opnsense_catchall\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/catchall.log\" ) Create rulesets \u00b6 Rulesets can be useful to chain incoming logs to a specific set of rules. ruleset ( name = \"r_opnsense\" ) { if $programname == 'filterlog' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_filterlog\" ) stop } if $programname == 'suricata' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_suricata\" ) stop } if $programname == 'openvpn' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_openvpn\" ) stop } if $programname == 'cron' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_cron\" ) stop } if $programname == 'squid' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_squid\" ) stop } if $programname == 'lighttpd' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_lighttpd\" ) stop } if $programname == 'dhcpd' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_dhcpd\" ) stop } *.* action ( type = \"omfile\" dynaFile = \"t_opnsense_catchall\" ) } Input Configuration \u00b6 Inputs can be specified with a ruleset to tie them to the previously create rules. input ( type = \"imudp\" port = \"514\" ruleset = \"r_opnsense\" ) Once the above has been configured, Save & Close the file. Then restart the rsyslog process: systemctl restart rsyslog Verify rsyslog is running with: systemctl status rsyslog Full Example /etc/rsyslog.conf # /etc/rsyslog.conf configuration file for rsyslog # # For more information install rsyslog-doc and see # /usr/share/doc/rsyslog-doc/html/configuration/index.html # # Default logging rules can be found in /etc/rsyslog.d/50-default.conf ################# #### MODULES #### ################# module ( load = \"imuxsock\" ) # provides support for local system logging #module(load=\"immark\") # provides --MARK-- message capability # provides UDP syslog reception module ( load = \"imudp\" ) # input(type=\"imudp\" port=\"514\") # provides TCP syslog reception #module(load=\"imtcp\") #input(type=\"imtcp\" port=\"514\") # provides kernel logging support and enable non-kernel klog messages module ( load = \"imklog\" permitnonkernelfacility = \"on\" ) ########################### #### GLOBAL DIRECTIVES #### ########################### # # OMFILE Global Permissions module ( load = \"builtin:omfile\" dirCreateMode = \"0750\" dirOwner = \"root\" dirGroup = \"splunk\" fileCreateMode = \"0640\" fileOwner = \"root\" fileGroup = \"splunk\" ) # Legacy Permissions $umask 0027 $DirCreateMode 0750 $FileCreateMode 0640 $DirGroup splunk $FileGroup splunk # Event Template template ( name = \"t_default\" type = \"list\" ) { property ( name = \"timestamp\" dateFormat = \"rfc3339\" ) constant ( value = \" \" ) property ( name = \"fromhost\" ) # can also be set to 'hostname' constant ( value = \" \" ) property ( name = \"syslogtag\" ) property ( name = \"msg\" spifno1stsp = \"on\" ) property ( name = \"msg\" droplastlf = \"on\" ) constant ( value = \"\\n\" ) } # # Use traditional timestamp format. # To enable high precision timestamps, comment out the following line. # # $ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat # Filter duplicated messages $RepeatedMsgReduction on # DynaFile Templates template ( name = \"t_opnsense_filterlog\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/filterlog.log\" ) template ( name = \"t_opnsense_suricata\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/suricata.log\" ) template ( name = \"t_opnsense_openvpn\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/openvpn.log\" ) template ( name = \"t_opnsense_cron\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/cron.log\" ) template ( name = \"t_opnsense_squid\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/squid.log\" ) template ( name = \"t_opnsense_lighttpd\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/lighttpd.log\" ) template ( name = \"t_opnsense_dhcpd\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/dhcpd.log\" ) template ( name = \"t_opnsense_catchall\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/catchall.log\" ) ruleset ( name = \"r_opnsense\" ) { if $programname == 'filterlog' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_filterlog\" ) stop } if $programname == 'suricata' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_suricata\" ) stop } if $programname == 'openvpn' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_openvpn\" ) stop } if $programname == 'cron' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_cron\" ) stop } if $programname == 'squid' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_squid\" ) stop } if $programname == 'lighttpd' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_lighttpd\" ) stop } if $programname == 'dhcpd' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_dhcpd\" ) stop } *.* action ( type = \"omfile\" dynaFile = \"t_opnsense_catchall\" ) } input ( type = \"imudp\" port = \"514\" ruleset = \"r_opnsense\" ) # # Where to place spool and state files # $WorkDirectory /var/spool/rsyslog # # Include all config files in /etc/rsyslog.d/ # $IncludeConfig /etc/rsyslog.d/*.conf Troubleshooting \u00b6 Ensure firewall rules are configured to allow the rsyslog listening port (514/udp) Ensure SELinux is not blocking rsyslog from writing to the file. This may occur if you write data outside of /var/log . Basic Log Rotation Strategy for syslog server \u00b6 It is necessary to rotate the logs to ensure the disk space does not fill up. Below is a basic example to get started with log rotation. The following uses the builtin package logrotate . The configuration file can be found at /etc/logrotate.conf Start by creating a new file in /etc/logrotate.d . For this example, we will use a created file in /etc/logrotate.d/opnsense Add the following to the file. /etc/logrotate.d/opnsense /var/log/remote/opnsense/*/*.log { rotate 7 daily missingok create 0640 root splunk notifempty compress createolddir 750 root splunk olddir /var/log/remote/old dateext dateformat -%Y-%m-%d dateyesterday sharedscripts postrotate /bin/kill -HUP ` cat /var/run/syslogd.pid 2 > /dev/null ` 2 > /dev/null || true endscript } The above may not work for every situation. Please check the man pages for logroate if experiencing issues. It may also be helpful to look at existing configuration files located in /etc/logrotate.d for reference. OPNsense Syslog Configuration \u00b6 The following is necessary to now send syslog data from the OPNsense firewall to the newly configured syslog server. Administrator access to the OPNsense Web GUI will be required to perform the following steps. Log into the OPNsense firewall. Navigate to: System > Settings > Logging/targets. Click the + (plus sign) to add a new syslog destination. Ensure the Enabled checkbox is checked. Transport = UDP(4) Applications = (Leave Blank) to select everything Levels = (Leave default setting) Facilities = (Leave Blank) to select everything Hostname = FQDN or IP of the syslog server configured in previous steps. Port = 514 Description = (Optional) Click Save Click Apply","title":"Syslog Configuration"},{"location":"guides/guide-syslog/#syslog-guide","text":"Sending data to a syslog server where a Splunk forwarder is monitoring the files can improve the data collection to Splunk. A Splunk forwarder automatically load-balances data to all indexers in a distributed environment and can be setup with TLS and other setting to ensure the data transmission is secure and reliable. Utilizing a syslog server will also help prevent gaps in data when Splunk needs to restart for maintenance or unplanned shutdowns. For more information see Splunk answers and Splunk Docs: Forwarder Manual . More information on syslog and Splunk, see the (SYSLOG) Syslog Data Collection section of the Splunk Validated Architectures white paper. The following will walk through an example of setting up syslog using Rsyslog. Syslog-ng example can be found at the below blog posts: High Performance Syslog - Part 1 High Performance Syslog - Part 2 Using Syslong-ng with Splunk","title":"Syslog Guide"},{"location":"guides/guide-syslog/#data-on-boarding-using-rsyslog","text":"Rsyslog is a default package on most linux distros. The OPNsense firewall can be setup to send logs via syslog to a configured Rsyslog server for a Splunk Forwarder to monitor. Below is a basic configuration to get started with data on-boarding. Note The following does not reflect rsyslog best practices but could be used as a starting point.","title":"Data on-boarding using Rsyslog"},{"location":"guides/guide-syslog/#rsyslog-basic-configuration","text":"Tested with Rsyslog version: rsyslogd 8.32.0 on RHEL/CentOS/Ubuntu The default rsyslog configuration file is located in /etc/rsyslog.conf . Open the rsyslog configuration file with your favorite text editor. Place the following in the configuration file or uncomment if already present:","title":"Rsyslog Basic Configuration"},{"location":"guides/guide-syslog/#load-modules","text":"Load in the appropriate modules for TCP/UDP module ( load = \"imudp\" ) # provides UDP syslog reception","title":"Load Modules"},{"location":"guides/guide-syslog/#file-permissions","text":"The following sets file permissions to root:splunk . # OMFILE Global Permissions module ( load = \"builtin:omfile\" dirCreateMode = \"0750\" dirOwner = \"root\" dirGroup = \"splunk\" fileCreateMode = \"0640\" fileOwner = \"root\" fileGroup = \"splunk\" ) # Legacy Permissions $umask 0027 $DirCreateMode 0750 $FileCreateMode 0640 $DirGroup splunk $FileGroup splunk","title":"File Permissions"},{"location":"guides/guide-syslog/#event-format-template","text":"The following is a standard example of how to set a template for an event format. This helps to standardize the logs to work better with Splunk. # Event Template template ( name = \"t_default\" type = \"list\" ) { property ( name = \"timestamp\" dateFormat = \"rfc3339\" ) constant ( value = \" \" ) property ( name = \"fromhost\" ) # can also be set to 'hostname' constant ( value = \" \" ) property ( name = \"syslogtag\" ) property ( name = \"msg\" spifno1stsp = \"on\" ) property ( name = \"msg\" droplastlf = \"on\" ) constant ( value = \"\\n\" ) } This will create events similar to the following: 2020 -02-16T22:47:31-00:00 myserver-003 named [ 32422 ] : 136299 10 .0.0.5/48300 reply apps.splunk.com is 52 .41.47.241","title":"Event Format Template"},{"location":"guides/guide-syslog/#dynamic-file-templates","text":"Create reusable templates for easy change-management template ( name = \"t_opnsense_filterlog\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/filterlog.log\" ) template ( name = \"t_opnsense_suricata\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/suricata.log\" ) template ( name = \"t_opnsense_openvpn\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/openvpn.log\" ) template ( name = \"t_opnsense_cron\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/cron.log\" ) template ( name = \"t_opnsense_squid\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/squid.log\" ) template ( name = \"t_opnsense_lighttpd\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/lighttpd.log\" ) template ( name = \"t_opnsense_dhcpd\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/dhcpd.log\" ) template ( name = \"t_opnsense_catchall\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/catchall.log\" )","title":"Dynamic File Templates"},{"location":"guides/guide-syslog/#create-rulesets","text":"Rulesets can be useful to chain incoming logs to a specific set of rules. ruleset ( name = \"r_opnsense\" ) { if $programname == 'filterlog' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_filterlog\" ) stop } if $programname == 'suricata' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_suricata\" ) stop } if $programname == 'openvpn' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_openvpn\" ) stop } if $programname == 'cron' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_cron\" ) stop } if $programname == 'squid' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_squid\" ) stop } if $programname == 'lighttpd' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_lighttpd\" ) stop } if $programname == 'dhcpd' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_dhcpd\" ) stop } *.* action ( type = \"omfile\" dynaFile = \"t_opnsense_catchall\" ) }","title":"Create rulesets"},{"location":"guides/guide-syslog/#input-configuration","text":"Inputs can be specified with a ruleset to tie them to the previously create rules. input ( type = \"imudp\" port = \"514\" ruleset = \"r_opnsense\" ) Once the above has been configured, Save & Close the file. Then restart the rsyslog process: systemctl restart rsyslog Verify rsyslog is running with: systemctl status rsyslog Full Example /etc/rsyslog.conf # /etc/rsyslog.conf configuration file for rsyslog # # For more information install rsyslog-doc and see # /usr/share/doc/rsyslog-doc/html/configuration/index.html # # Default logging rules can be found in /etc/rsyslog.d/50-default.conf ################# #### MODULES #### ################# module ( load = \"imuxsock\" ) # provides support for local system logging #module(load=\"immark\") # provides --MARK-- message capability # provides UDP syslog reception module ( load = \"imudp\" ) # input(type=\"imudp\" port=\"514\") # provides TCP syslog reception #module(load=\"imtcp\") #input(type=\"imtcp\" port=\"514\") # provides kernel logging support and enable non-kernel klog messages module ( load = \"imklog\" permitnonkernelfacility = \"on\" ) ########################### #### GLOBAL DIRECTIVES #### ########################### # # OMFILE Global Permissions module ( load = \"builtin:omfile\" dirCreateMode = \"0750\" dirOwner = \"root\" dirGroup = \"splunk\" fileCreateMode = \"0640\" fileOwner = \"root\" fileGroup = \"splunk\" ) # Legacy Permissions $umask 0027 $DirCreateMode 0750 $FileCreateMode 0640 $DirGroup splunk $FileGroup splunk # Event Template template ( name = \"t_default\" type = \"list\" ) { property ( name = \"timestamp\" dateFormat = \"rfc3339\" ) constant ( value = \" \" ) property ( name = \"fromhost\" ) # can also be set to 'hostname' constant ( value = \" \" ) property ( name = \"syslogtag\" ) property ( name = \"msg\" spifno1stsp = \"on\" ) property ( name = \"msg\" droplastlf = \"on\" ) constant ( value = \"\\n\" ) } # # Use traditional timestamp format. # To enable high precision timestamps, comment out the following line. # # $ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat # Filter duplicated messages $RepeatedMsgReduction on # DynaFile Templates template ( name = \"t_opnsense_filterlog\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/filterlog.log\" ) template ( name = \"t_opnsense_suricata\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/suricata.log\" ) template ( name = \"t_opnsense_openvpn\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/openvpn.log\" ) template ( name = \"t_opnsense_cron\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/cron.log\" ) template ( name = \"t_opnsense_squid\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/squid.log\" ) template ( name = \"t_opnsense_lighttpd\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/lighttpd.log\" ) template ( name = \"t_opnsense_dhcpd\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/dhcpd.log\" ) template ( name = \"t_opnsense_catchall\" type = \"string\" string = \"/var/log/remote/opnsense/%HOSTNAME%/catchall.log\" ) ruleset ( name = \"r_opnsense\" ) { if $programname == 'filterlog' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_filterlog\" ) stop } if $programname == 'suricata' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_suricata\" ) stop } if $programname == 'openvpn' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_openvpn\" ) stop } if $programname == 'cron' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_cron\" ) stop } if $programname == 'squid' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_squid\" ) stop } if $programname == 'lighttpd' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_lighttpd\" ) stop } if $programname == 'dhcpd' then { action ( type = \"omfile\" dynaFile = \"t_opnsense_dhcpd\" ) stop } *.* action ( type = \"omfile\" dynaFile = \"t_opnsense_catchall\" ) } input ( type = \"imudp\" port = \"514\" ruleset = \"r_opnsense\" ) # # Where to place spool and state files # $WorkDirectory /var/spool/rsyslog # # Include all config files in /etc/rsyslog.d/ # $IncludeConfig /etc/rsyslog.d/*.conf","title":"Input Configuration"},{"location":"guides/guide-syslog/#troubleshooting","text":"Ensure firewall rules are configured to allow the rsyslog listening port (514/udp) Ensure SELinux is not blocking rsyslog from writing to the file. This may occur if you write data outside of /var/log .","title":"Troubleshooting"},{"location":"guides/guide-syslog/#basic-log-rotation-strategy-for-syslog-server","text":"It is necessary to rotate the logs to ensure the disk space does not fill up. Below is a basic example to get started with log rotation. The following uses the builtin package logrotate . The configuration file can be found at /etc/logrotate.conf Start by creating a new file in /etc/logrotate.d . For this example, we will use a created file in /etc/logrotate.d/opnsense Add the following to the file. /etc/logrotate.d/opnsense /var/log/remote/opnsense/*/*.log { rotate 7 daily missingok create 0640 root splunk notifempty compress createolddir 750 root splunk olddir /var/log/remote/old dateext dateformat -%Y-%m-%d dateyesterday sharedscripts postrotate /bin/kill -HUP ` cat /var/run/syslogd.pid 2 > /dev/null ` 2 > /dev/null || true endscript } The above may not work for every situation. Please check the man pages for logroate if experiencing issues. It may also be helpful to look at existing configuration files located in /etc/logrotate.d for reference.","title":"Basic Log Rotation Strategy for syslog server"},{"location":"guides/guide-syslog/#opnsense-syslog-configuration","text":"The following is necessary to now send syslog data from the OPNsense firewall to the newly configured syslog server. Administrator access to the OPNsense Web GUI will be required to perform the following steps. Log into the OPNsense firewall. Navigate to: System > Settings > Logging/targets. Click the + (plus sign) to add a new syslog destination. Ensure the Enabled checkbox is checked. Transport = UDP(4) Applications = (Leave Blank) to select everything Levels = (Leave default setting) Facilities = (Leave Blank) to select everything Hostname = FQDN or IP of the syslog server configured in previous steps. Port = 514 Description = (Optional) Click Save Click Apply","title":"OPNsense Syslog Configuration"},{"location":"reference/reference-mod-input/","text":"Modular Input Details \u00b6 The Modular input pulls select system information from the firewall. Future releases may include additional information. The following table shows the information collected by this input. Collection Type Description System System information including OS, OPNsense Version, Available Updates. Packages Packages installed on the system. Plugins Plugins installed on the system.","title":"Modular Input Reference"},{"location":"reference/reference-mod-input/#modular-input-details","text":"The Modular input pulls select system information from the firewall. Future releases may include additional information. The following table shows the information collected by this input. Collection Type Description System System information including OS, OPNsense Version, Available Updates. Packages Packages installed on the system. Plugins Plugins installed on the system.","title":"Modular Input Details"},{"location":"reference/reference-sourcetypes/","text":"Sourcetypes \u00b6 Below are a list of sourcetypes which this Add-on uses. It is not necessary to manually set the sourcetype to anything other than opnsense as this add-on will automatically transform the sourcetype to the appropriate value. Source type Description CIM Mapping opnsense:access deprecated v1.5.0 Access Events to OPNsense firewall. Authentication opnsense:audit new v1.5.0 Audit Events to OPNsense firewall (logins/changes). Authentication opnsense:cron Cron Events None opnsense:dhcpd DHCP Events Network Sessions opnsense:filterlog Filterlog Events Network Traffic opnsense:lighttpd Events from the Web interface Web opnsense:openvpn OpenVPN Events Authentication opnsense:suricata opnsense:suricata:json IDS events from suricata Intrusion Detection Network Traffic opnsense:squid Proxy events from Squid Proxy Web opnsense:unbound DNS events from Unbound DNS Network Resolution opnsense:syslog Events from Syslog-ng None","title":"Sourectypes"},{"location":"reference/reference-sourcetypes/#sourcetypes","text":"Below are a list of sourcetypes which this Add-on uses. It is not necessary to manually set the sourcetype to anything other than opnsense as this add-on will automatically transform the sourcetype to the appropriate value. Source type Description CIM Mapping opnsense:access deprecated v1.5.0 Access Events to OPNsense firewall. Authentication opnsense:audit new v1.5.0 Audit Events to OPNsense firewall (logins/changes). Authentication opnsense:cron Cron Events None opnsense:dhcpd DHCP Events Network Sessions opnsense:filterlog Filterlog Events Network Traffic opnsense:lighttpd Events from the Web interface Web opnsense:openvpn OpenVPN Events Authentication opnsense:suricata opnsense:suricata:json IDS events from suricata Intrusion Detection Network Traffic opnsense:squid Proxy events from Squid Proxy Web opnsense:unbound DNS events from Unbound DNS Network Resolution opnsense:syslog Events from Syslog-ng None","title":"Sourcetypes"},{"location":"reference/releases/","text":"Release notes for the OPNsense Add-on for Splunk \u00b6 v1.5.1 Nov 30, 2021 \u00b6 Warning Only applies if you are upgrading from a version < 1.5.0 This version includes packages for the new version of Add-on builder (v4.0.0) which may cause API credentials to no longer work after updating. After updating to this version, you may have to re-enter the API credentials for the modular inputs to work again by editing the existing account configurations. New features \u00b6 Adding default allowed action for suricata events Fixed issues \u00b6 Updating field extractions for Suricata events in Drop mode - #58 Fixed certificate issue when no cert checking is enabled - #61 Known issues \u00b6 This version of the OPNsense addon for Splunk has the following known issues. If no issues appear here, no issues have been reported. Issues can be reported on the OPNsense addon for Splunk's Github page .","title":"Release Notes"},{"location":"reference/releases/#release-notes-for-the-opnsense-add-on-for-splunk","text":"","title":"Release notes for the OPNsense Add-on for Splunk"},{"location":"reference/releases/#v151-nov-30-2021","text":"Warning Only applies if you are upgrading from a version < 1.5.0 This version includes packages for the new version of Add-on builder (v4.0.0) which may cause API credentials to no longer work after updating. After updating to this version, you may have to re-enter the API credentials for the modular inputs to work again by editing the existing account configurations.","title":"v1.5.1 Nov 30, 2021"},{"location":"reference/releases/#new-features","text":"Adding default allowed action for suricata events","title":"New features"},{"location":"reference/releases/#fixed-issues","text":"Updating field extractions for Suricata events in Drop mode - #58 Fixed certificate issue when no cert checking is enabled - #61","title":"Fixed issues"},{"location":"reference/releases/#known-issues","text":"This version of the OPNsense addon for Splunk has the following known issues. If no issues appear here, no issues have been reported. Issues can be reported on the OPNsense addon for Splunk's Github page .","title":"Known issues"},{"location":"reference/releases/release-history/","text":"Release history for the OPNsense addon for Splunk \u00b6 The latest version of the OPNsense addon for Splunk is version 1.5.1. See Release notes for the OPNsense addon for Splunk of the latest version. v1.5.0 Aug 7, 2021 \u00b6 Warning This version includes packages for the new version of Add-on builder (v4.0.0) which may cause API credentials to no longer work after updating. After updating to this version, you may have to re-enter the API credentials for the modular inputs to work again by editing the existing account configurations. deprecating sourcetype \"opnsense:access\" and moving to \"opnsense:audit\" updated CIM mapping for Authentication events updated to latest add-on builder version v1.4.3 July 8, 2021 \u00b6 fixed script to initial an upgrade check - #49 added ability to use a cron schedule for the modular input interval - #52 added ability to specify port number for modular input - #53 v1.4.2 June 2, 2021 \u00b6 Adding support for absolute paths in modular input setup for certificates - #44 Fixed issue with the Verify Certificate checkbox not working properly - #47 v1.4.1 May 27, 2021 \u00b6 Fixed incorrect sourcetype transform for modular input - issue #41 Increased the truncate limit to allow large events. v1.4.0 May 27, 2021 \u00b6 Added modular input to pull system information (Available Updates, Versions, Installed Packages/Plugins). Updated the suricata sourcetyper to recognize the json data without the standard syslog message header. Fixed ipv6 ICMP events not extracting properly - issue #37 v1.3.2 Dec 14, 2020 \u00b6 Added meta field for event length (opnsense_event_length). Added sourcetype for Syslog-ng logs (opnsense:syslog). Added action for \"Redirect\" if port forwarding logging rules exist. Fixed \"unknown\" severity for opnsense:suricata:json events - issue #27 . Fixed IGMP events not being extracted - issue #32 . Fixed Access logs not being extracted - issue #35 . v1.3.1 Oct 31, 2020 \u00b6 fixed KV_MODE for opnsense:unbound sourcetype. v1.3.0 Aug 15, 2020 \u00b6 Added compatibility for eve syslog format for Suricata events. Removed incorrect field extraction for DHCP events. v1.2.9 Aug 5, 2020 \u00b6 Added compatibility for new syslog format released in OPNSense v20.7. Updated the 'vendor_options' field to be multi-valued. Appinspect fixes. v1.2.7 Jul 15, 2020 \u00b6 Removed Dependency for CIM app. Fixed multiple regex statements under one stanza.","title":"Release History"},{"location":"reference/releases/release-history/#release-history-for-the-opnsense-addon-for-splunk","text":"The latest version of the OPNsense addon for Splunk is version 1.5.1. See Release notes for the OPNsense addon for Splunk of the latest version.","title":"Release history for the OPNsense addon for Splunk"},{"location":"reference/releases/release-history/#v150-aug-7-2021","text":"Warning This version includes packages for the new version of Add-on builder (v4.0.0) which may cause API credentials to no longer work after updating. After updating to this version, you may have to re-enter the API credentials for the modular inputs to work again by editing the existing account configurations. deprecating sourcetype \"opnsense:access\" and moving to \"opnsense:audit\" updated CIM mapping for Authentication events updated to latest add-on builder version","title":"v1.5.0 Aug 7, 2021"},{"location":"reference/releases/release-history/#v143-july-8-2021","text":"fixed script to initial an upgrade check - #49 added ability to use a cron schedule for the modular input interval - #52 added ability to specify port number for modular input - #53","title":"v1.4.3 July 8, 2021"},{"location":"reference/releases/release-history/#v142-june-2-2021","text":"Adding support for absolute paths in modular input setup for certificates - #44 Fixed issue with the Verify Certificate checkbox not working properly - #47","title":"v1.4.2 June 2, 2021"},{"location":"reference/releases/release-history/#v141-may-27-2021","text":"Fixed incorrect sourcetype transform for modular input - issue #41 Increased the truncate limit to allow large events.","title":"v1.4.1 May 27, 2021"},{"location":"reference/releases/release-history/#v140-may-27-2021","text":"Added modular input to pull system information (Available Updates, Versions, Installed Packages/Plugins). Updated the suricata sourcetyper to recognize the json data without the standard syslog message header. Fixed ipv6 ICMP events not extracting properly - issue #37","title":"v1.4.0 May 27, 2021"},{"location":"reference/releases/release-history/#v132-dec-14-2020","text":"Added meta field for event length (opnsense_event_length). Added sourcetype for Syslog-ng logs (opnsense:syslog). Added action for \"Redirect\" if port forwarding logging rules exist. Fixed \"unknown\" severity for opnsense:suricata:json events - issue #27 . Fixed IGMP events not being extracted - issue #32 . Fixed Access logs not being extracted - issue #35 .","title":"v1.3.2 Dec 14, 2020"},{"location":"reference/releases/release-history/#v131-oct-31-2020","text":"fixed KV_MODE for opnsense:unbound sourcetype.","title":"v1.3.1 Oct 31, 2020"},{"location":"reference/releases/release-history/#v130-aug-15-2020","text":"Added compatibility for eve syslog format for Suricata events. Removed incorrect field extraction for DHCP events.","title":"v1.3.0 Aug 15, 2020"},{"location":"reference/releases/release-history/#v129-aug-5-2020","text":"Added compatibility for new syslog format released in OPNSense v20.7. Updated the 'vendor_options' field to be multi-valued. Appinspect fixes.","title":"v1.2.9 Aug 5, 2020"},{"location":"reference/releases/release-history/#v127-jul-15-2020","text":"Removed Dependency for CIM app. Fixed multiple regex statements under one stanza.","title":"v1.2.7 Jul 15, 2020"}]}